# Real-or-AI-Image

## Introduction

With the advancement of AI, it's easy to synthesis images from scratch. This technology indeed benefit humankind in some ways yet it also makes people worried about the credibilty of images. In view of this, our project's main goal is to identify whether the image is synthesised by AI. We implement several models and the result can help us identify image received is genuine resource.

## Related Work

[CIFAKE: Real and AI-Generated Synthetic Images](https://www.kaggle.com/datasets/birdy654/cifake-real-and-ai-generated-synthetic-images)

## Requirements

```
jupyter==1.0.0
matplotlib==3.7.1
numpy==1.24.3
opencv-python==4.7.0.72
pandas==2.0.1
scikit-learn==1.2.2
tensorflow==2.10.1
tqdm==4.65.0
```

## Baseline

The basic Convolution Neural Network (CNN) is our baseline model.

## Main Approach

We choose **ResNet50** and **EfficientNetV2** with **transfer learning** as our main approaches.

## Hyperparameter
CNN : lr = 0.001, batch\_size = 200, and epochs = 20

ResNet50 : lr = 0.0007, batch\_size = 200, and epochs = 20

EfficientNetV2 : lr = 0.001, batch\_size = 200, and epochs = 20

## Evaluation Metrics
### Accuracy
$$accuracy = \frac{1}{n}\sum_{i=1}^n f(x)\quad where\ f(x)=
\begin{cases}
1, & if\ output=label \\ 
0, & otherwise 
\end{cases}$$

### F1-score

Define four paramaters as followed:

> TP : Number of samples correctly predicted as “real image.”
> 
> TN : Number of samples correctly predicted as “AI image.”
> 
> FP : Number of samples wrongly predicted as “real image.”
> 
> FN : Number of samples wrongly predicted as “AI image.”

**Formula** :

$$Recall = \frac{TP}{TP+FN}$$

$$Precision = \frac{TP}{TP+FP}$$

$$F1-score = \frac{2\times Precision \times Recall}{Precision+Recall}$$

## Results
CNN : accuracy = 0.88, f1-score = 0.88

ResNet50 : accuracy = 0.93, f1-score = 0.93

EfficientNetV2 : accuracy = 0.95, f1-score = 0.95

## Advanced Experiment

Besides stable diffusion synthesised dataset, we train a DCGAN model using the CIFAKE images as our dataset, and then generate the images to test our models. However, we obtain low accuracy in the result, which means that both has difficulty to classify DCGAN generated images. 

Thus, to improve our model, we train another model using EfficientNetV2 by adding DCGAN images as our dataset, and the hyperparameter of this improved model are same as the EfficientNetV2 above. 

Finally, we get an ideal result, which accuracy = 0.9575, f1-score = 0.96 ,and the model can identify the CIFAKE images and the DCGAN images generated by us successfully.

## Reference

[Krizhevsky, A., &amp; Hinton, G. (2009). Learning multiple layers of features from tiny images](https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdfl)

[Bird, J.J., Lotfi, A. (2023). CIFAKE: Image Classification and Explainable Identification of AI-Generated Synthetic Images. arXiv preprint arXiv:2303.14126](https://arxiv.org/abs/2303.14126)

[Review — EfficientNetV2: Smaller Models and Faster Training](https://medium.com/aiguys/review-efficientnetv2-smaller-models-and-faster-training-47d4215dcdfb)

[Introduction to ResNets](https://towardsdatascience.com/introduction-to-resnets-c0a830a288a4)

[DCGAN: Deep Convolutional Generative Adversarial Network](https://medium.com/swlh/dcgan-deep-convolutional-generative-adversarial-network-1a2e55c35133)
