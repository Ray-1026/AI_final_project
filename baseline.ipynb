{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from tensorflow import keras, config\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainData():\n",
    "    fake_img = r\"archive\\train\\FAKE\"\n",
    "    real_img = r\"archive\\train\\REAL\"\n",
    "    image = []\n",
    "    label = []\n",
    "    aug_img = []\n",
    "    aug_label = []\n",
    "\n",
    "    random_fake = np.random.choice(os.listdir(fake_img), 40000, replace=False)\n",
    "    random_real = np.random.choice(os.listdir(real_img), 40000, replace=False)\n",
    "\n",
    "    # Set 0 to represent fake, and 1 to represent real\n",
    "    for path in tqdm(random_fake[:20000], desc='Fake Training Data'):\n",
    "        data = cv2.imread(os.path.join(fake_img, path))\n",
    "        image.append(data)\n",
    "        label.append(0)\n",
    "\n",
    "    for path in tqdm(random_fake[20000:], desc='Fake Training Data (to be augmented)'):\n",
    "        data = cv2.imread(os.path.join(fake_img, path))\n",
    "        aug_img.append(data)\n",
    "        aug_label.append(0)\n",
    "\n",
    "    for path in tqdm(random_real[:20000], desc='Real Training Data'):\n",
    "        data = cv2.imread(os.path.join(real_img, path))\n",
    "        image.append(data)\n",
    "        label.append(1)\n",
    "\n",
    "    for path in tqdm(random_real[20000:], desc='Real Training Data (to be augmented)'):\n",
    "        data = cv2.imread(os.path.join(real_img, path))\n",
    "        aug_img.append(data)\n",
    "        aug_label.append(1)\n",
    "\n",
    "    print()\n",
    "    # image augmantation\n",
    "    aug_img = np.array(aug_img).reshape(-1, 32, 32, 3)\n",
    "    aug_label = np.array(aug_label)\n",
    "    gen_image = []\n",
    "    gen_label = []\n",
    "    gen = ImageDataGenerator(\n",
    "        rotation_range=45,\n",
    "        horizontal_flip = True,\n",
    "    )\n",
    "    gen.fit(aug_img)\n",
    "\n",
    "    for i, j in gen.flow(aug_img, aug_label, batch_size=200):\n",
    "        gen_image.append(i)\n",
    "        gen_label.append(j)\n",
    "        if len(gen_image)%50==0:\n",
    "            print(f'{len(gen_image)*200}/40000 augmented data generated.')\n",
    "        if len(gen_image)==200:\n",
    "            print('Data augmentation done')\n",
    "            break\n",
    "    gen_image = np.concatenate(gen_image)\n",
    "    gen_label = np.array(gen_label).flatten()\n",
    "\n",
    "    print(f'\\nOrigin training data : {len(image)}')\n",
    "    print(f'Augmented training data : {len(gen_image)}')\n",
    "\n",
    "    image = np.array(image).reshape(-1, 32, 32, 3)\n",
    "    label = np.array(label)\n",
    "\n",
    "    image = np.concatenate((image, gen_image))\n",
    "    label = np.concatenate((label, gen_label))\n",
    "    image = image/255.0\n",
    "\n",
    "    state = np.random.get_state()\n",
    "    np.random.shuffle(image)\n",
    "    np.random.set_state(state)\n",
    "    np.random.shuffle(label)\n",
    "    print('\\nShuffle training data done.\\n')\n",
    "    print(f'Total training data : {len(image)}')\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestData():\n",
    "    fake_path = r\"archive\\test\\FAKE\"\n",
    "    real_path = r\"archive\\test\\REAL\"\n",
    "    image = []\n",
    "    label = []\n",
    "    # Set 0 to represent fake, and 1 to represent real\n",
    "    for path in tqdm(os.listdir(fake_path), desc='Fake Testing Data'):\n",
    "        data = cv2.imread(os.path.join(fake_path, path))\n",
    "        image.append(data)\n",
    "        label.append(0)\n",
    "    \n",
    "    for path in tqdm(os.listdir(real_path), desc='Real Testing Data'):\n",
    "        data = cv2.imread(os.path.join(real_path, path))\n",
    "        image.append(data)\n",
    "        label.append(1)\n",
    "\n",
    "    image=np.array(image).reshape(-1, 32, 32, 3)\n",
    "    image=image/255\n",
    "    label=np.array(label)\n",
    "\n",
    "    return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fake Training Data: 100%|██████████| 20000/20000 [04:53<00:00, 68.20it/s]\n",
      "Fake Training Data (to be augmented):  90%|████████▉ | 17950/20000 [04:31<00:31, 66.00it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_x, train_y \u001b[39m=\u001b[39m TrainData()\n",
      "Cell \u001b[1;32mIn[38], line 19\u001b[0m, in \u001b[0;36mTrainData\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m     label\u001b[39m.\u001b[39mappend(\u001b[39m0\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[39mfor\u001b[39;00m path \u001b[39min\u001b[39;00m tqdm(random_fake[\u001b[39m20000\u001b[39m:], desc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFake Training Data (to be augmented)\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m---> 19\u001b[0m     data \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mimread(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(fake_img, path))\n\u001b[0;32m     20\u001b[0m     aug_img\u001b[39m.\u001b[39mappend(data)\n\u001b[0;32m     21\u001b[0m     aug_label\u001b[39m.\u001b[39mappend(\u001b[39m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_x, train_y = TrainData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fake Testing Data: 100%|██████████| 10000/10000 [01:00<00:00, 164.00it/s]\n",
      "Real Testing Data: 100%|██████████| 10000/10000 [00:13<00:00, 738.10it/s]\n"
     ]
    }
   ],
   "source": [
    "test_x, test_y = TestData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Tensorflow supports running computations on GPU \n",
    "\n",
    "WARNING : You need to have CUDA, cuDNN, and tensorflow with version lower than 2.11.0, \n",
    "          if not, DON'T execute this cell.\n",
    "\"\"\"\n",
    "physical_devices = config.list_physical_devices('GPU')\n",
    "config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "print('Running on GPU available now')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 30, 30, 64)        1792      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 15, 15, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 13, 13, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                147520    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 186,305\n",
      "Trainable params: 186,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 29/400 [=>............................] - ETA: 53s - loss: 0.2056 - accuracy: 0.9147"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m test_ac, test_loss \u001b[39m=\u001b[39m [], []\n\u001b[0;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m11\u001b[39m):\n\u001b[1;32m----> 5\u001b[0m     history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(aug_train_x, aug_train_y, epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m)\n\u001b[0;32m      6\u001b[0m     loss, ac \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(test_x, test_y)\n\u001b[0;32m      8\u001b[0m     train_loss\u001b[39m.\u001b[39mappend(history\u001b[39m.\u001b[39mhostory[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_ac, train_loss = [], []\n",
    "test_ac, test_loss = [], []\n",
    "\n",
    "for epoch in range(1, 11):\n",
    "    history = model.fit(train_x, train_y, epochs=1, batch_size=200)\n",
    "    loss, ac = model.evaluate(test_x, test_y)\n",
    "\n",
    "    train_loss.append(history.hostory['loss'])\n",
    "    train_ac.append(history.history['accuaracy'])\n",
    "    test_loss.append(loss)\n",
    "    test_ac.append(ac)\n",
    "    # prediction = model.predict(test_x)\n",
    "    # prediction = [int(np.round(prediction[p])) for p in range(len(prediction))]\n",
    "    # ac2=0\n",
    "    # for i, j in zip(test_y, prediction):\n",
    "    #     if i==j:\n",
    "    #         ac2+=1\n",
    "    # print(ac, ac2/len(prediction), end=' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'History' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Plot the loss and accuracy of training set.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m plt\u001b[39m.\u001b[39msubplot(\u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m plt\u001b[39m.\u001b[39mplot(history[\u001b[39m'\u001b[39;49m\u001b[39mloss\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m      5\u001b[0m plt\u001b[39m.\u001b[39mplot(test_loss)\n\u001b[0;32m      6\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m'\u001b[39m\u001b[39mModel Loss\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'History' object is not subscriptable"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss and accuracy of training set.\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_loss)\n",
    "plt.plot(test_loss)\n",
    "plt.axis([0, 10, 0, 1])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_ac)\n",
    "plt.plot(test_ac)\n",
    "plt.axis([0, 10, 0, 100])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
